{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission.*\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgement: This exercise is adapted from [Stanford CS231n](http://cs231n.stanford.edu/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(out, correct_out):\n",
    "    return np.sum(abs(out - correct_out) / (abs(out) + abs(correct_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    Softmax, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    # # We will also make a development set, which is a small subset of\n",
    "    # the training set.\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "\n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "\n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot vectors for label\n",
    "num_class = 10\n",
    "y_train_oh = np.zeros((y_train.shape[0], 10))\n",
    "y_train_oh[np.arange(y_train.shape[0]), y_train] = 1\n",
    "y_val_oh = np.zeros((y_val.shape[0], 10))\n",
    "y_val_oh[np.arange(y_val.shape[0]), y_val] = 1\n",
    "y_test_oh = np.zeros((y_test.shape[0], 10))\n",
    "y_test_oh[np.arange(y_test.shape[0]), y_test] = 1\n",
    "\n",
    "y_dev_oh = np.zeros((y_dev.shape[0], 10))\n",
    "y_dev_oh[np.arange(y_dev.shape[0]), y_dev] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression as classifier\n",
    "The most simple and straightforward approach to learn a classifier is to map the input data (raw image values) to class label (one-hot vector). The loss function is defined as following: \n",
    "$$\\mathcal{L}=\\frac{1}{n}\\|\\mathbf{X}\\mathbf{W}-\\mathbf{y}\\|_F^2\\qquad\\qquad(1)$$\n",
    "Where:\n",
    "* $\\mathbf{W}\\in \\mathbb{R}^{(d+1)\\times C}$: Classifier weight\n",
    "* $\\mathbf{X}\\in \\mathbb{R}^{n\\times (d+1)}$: Dataset\n",
    "* $\\mathbf{y}\\in \\mathbb{R}^{n\\times C}$: Class label (one-hot vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "Given the loss function (1), the next problem is how to solve the weight $\\mathbf{W}$. We now discuss 2 approaches: \n",
    " * Random search\n",
    " * Closed-form solution\n",
    "\n",
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in attempt 0 the loss was 34.584989, best 34.584989\n",
      "in attempt 1 the loss was 32.742228, best 32.742228\n",
      "in attempt 2 the loss was 33.160128, best 32.742228\n",
      "in attempt 3 the loss was 33.415307, best 32.742228\n",
      "in attempt 4 the loss was 30.138346, best 30.138346\n",
      "in attempt 5 the loss was 34.948674, best 30.138346\n",
      "in attempt 6 the loss was 32.965973, best 30.138346\n",
      "in attempt 7 the loss was 34.918137, best 30.138346\n",
      "in attempt 8 the loss was 32.294794, best 30.138346\n",
      "in attempt 9 the loss was 32.126874, best 30.138346\n",
      "in attempt 10 the loss was 31.166088, best 30.138346\n",
      "in attempt 11 the loss was 34.075411, best 30.138346\n",
      "in attempt 12 the loss was 31.195480, best 30.138346\n",
      "in attempt 13 the loss was 32.638493, best 30.138346\n",
      "in attempt 14 the loss was 37.145719, best 30.138346\n",
      "in attempt 15 the loss was 35.623509, best 30.138346\n",
      "in attempt 16 the loss was 32.539644, best 30.138346\n",
      "in attempt 17 the loss was 32.865098, best 30.138346\n",
      "in attempt 18 the loss was 33.973129, best 30.138346\n",
      "in attempt 19 the loss was 32.522084, best 30.138346\n",
      "in attempt 20 the loss was 32.957806, best 30.138346\n",
      "in attempt 21 the loss was 33.585979, best 30.138346\n",
      "in attempt 22 the loss was 32.507745, best 30.138346\n",
      "in attempt 23 the loss was 34.235534, best 30.138346\n",
      "in attempt 24 the loss was 32.319535, best 30.138346\n",
      "in attempt 25 the loss was 33.779677, best 30.138346\n",
      "in attempt 26 the loss was 32.288827, best 30.138346\n",
      "in attempt 27 the loss was 33.289435, best 30.138346\n",
      "in attempt 28 the loss was 32.868451, best 30.138346\n",
      "in attempt 29 the loss was 32.106525, best 30.138346\n",
      "in attempt 30 the loss was 33.924781, best 30.138346\n",
      "in attempt 31 the loss was 32.749890, best 30.138346\n",
      "in attempt 32 the loss was 37.061445, best 30.138346\n",
      "in attempt 33 the loss was 30.424137, best 30.138346\n",
      "in attempt 34 the loss was 34.672037, best 30.138346\n",
      "in attempt 35 the loss was 33.579730, best 30.138346\n",
      "in attempt 36 the loss was 35.456837, best 30.138346\n",
      "in attempt 37 the loss was 33.319212, best 30.138346\n",
      "in attempt 38 the loss was 32.360866, best 30.138346\n",
      "in attempt 39 the loss was 36.350859, best 30.138346\n",
      "in attempt 40 the loss was 34.209386, best 30.138346\n",
      "in attempt 41 the loss was 34.008904, best 30.138346\n",
      "in attempt 42 the loss was 33.750351, best 30.138346\n",
      "in attempt 43 the loss was 34.551746, best 30.138346\n",
      "in attempt 44 the loss was 33.940903, best 30.138346\n",
      "in attempt 45 the loss was 34.247738, best 30.138346\n",
      "in attempt 46 the loss was 32.590547, best 30.138346\n",
      "in attempt 47 the loss was 35.363875, best 30.138346\n",
      "in attempt 48 the loss was 35.369957, best 30.138346\n",
      "in attempt 49 the loss was 33.035071, best 30.138346\n",
      "in attempt 50 the loss was 37.049055, best 30.138346\n",
      "in attempt 51 the loss was 32.885168, best 30.138346\n",
      "in attempt 52 the loss was 31.628220, best 30.138346\n",
      "in attempt 53 the loss was 33.244617, best 30.138346\n",
      "in attempt 54 the loss was 34.467995, best 30.138346\n",
      "in attempt 55 the loss was 34.363314, best 30.138346\n",
      "in attempt 56 the loss was 35.917236, best 30.138346\n",
      "in attempt 57 the loss was 32.522759, best 30.138346\n",
      "in attempt 58 the loss was 32.768395, best 30.138346\n",
      "in attempt 59 the loss was 35.309257, best 30.138346\n",
      "in attempt 60 the loss was 33.347134, best 30.138346\n",
      "in attempt 61 the loss was 33.450936, best 30.138346\n",
      "in attempt 62 the loss was 32.831332, best 30.138346\n",
      "in attempt 63 the loss was 32.640132, best 30.138346\n",
      "in attempt 64 the loss was 32.810023, best 30.138346\n",
      "in attempt 65 the loss was 34.843470, best 30.138346\n",
      "in attempt 66 the loss was 33.290925, best 30.138346\n",
      "in attempt 67 the loss was 36.720599, best 30.138346\n",
      "in attempt 68 the loss was 33.134931, best 30.138346\n",
      "in attempt 69 the loss was 32.255803, best 30.138346\n",
      "in attempt 70 the loss was 32.640937, best 30.138346\n",
      "in attempt 71 the loss was 32.591734, best 30.138346\n",
      "in attempt 72 the loss was 33.997416, best 30.138346\n",
      "in attempt 73 the loss was 34.428395, best 30.138346\n",
      "in attempt 74 the loss was 31.865540, best 30.138346\n",
      "in attempt 75 the loss was 34.075230, best 30.138346\n",
      "in attempt 76 the loss was 32.786628, best 30.138346\n",
      "in attempt 77 the loss was 33.204334, best 30.138346\n",
      "in attempt 78 the loss was 33.501741, best 30.138346\n",
      "in attempt 79 the loss was 33.501285, best 30.138346\n",
      "in attempt 80 the loss was 32.429033, best 30.138346\n",
      "in attempt 81 the loss was 33.193304, best 30.138346\n",
      "in attempt 82 the loss was 33.659201, best 30.138346\n",
      "in attempt 83 the loss was 35.416439, best 30.138346\n",
      "in attempt 84 the loss was 33.040760, best 30.138346\n",
      "in attempt 85 the loss was 33.297539, best 30.138346\n",
      "in attempt 86 the loss was 34.237956, best 30.138346\n",
      "in attempt 87 the loss was 31.215583, best 30.138346\n",
      "in attempt 88 the loss was 32.738583, best 30.138346\n",
      "in attempt 89 the loss was 34.129418, best 30.138346\n",
      "in attempt 90 the loss was 33.061938, best 30.138346\n",
      "in attempt 91 the loss was 33.802207, best 30.138346\n",
      "in attempt 92 the loss was 32.481785, best 30.138346\n",
      "in attempt 93 the loss was 34.712956, best 30.138346\n",
      "in attempt 94 the loss was 33.498338, best 30.138346\n",
      "in attempt 95 the loss was 37.406749, best 30.138346\n",
      "in attempt 96 the loss was 32.674211, best 30.138346\n",
      "in attempt 97 the loss was 32.395267, best 30.138346\n",
      "in attempt 98 the loss was 33.646270, best 30.138346\n",
      "in attempt 99 the loss was 32.294125, best 30.138346\n"
     ]
    }
   ],
   "source": [
    "bestloss = float('inf')\n",
    "for num in range(100):\n",
    "    W = np.random.randn(3073, 10) * 0.0001\n",
    "    loss = np.linalg.norm(X_dev.dot(W) - y_dev_oh)\n",
    "    if (loss < bestloss):\n",
    "        bestloss = loss\n",
    "        bestW = W\n",
    "    print('in attempt %d the loss was %f, best %f' % (num, loss, bestloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:  9.4\n",
      "Accuracy on test set:  8.7\n"
     ]
    }
   ],
   "source": [
    "# How bestW perform:\n",
    "print('Accuracy on train set: ', np.sum(np.argmin(np.abs(1 - X_dev.dot(W)), axis=1) == y_dev).astype(np.float32)/y_dev.shape[0]*100)\n",
    "print('Accuracy on test set: ', np.sum(np.argmin(np.abs(1 - X_test.dot(W)), axis=1) == y_test).astype(np.float32)/y_test.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see that the performance is very low, almost at the random level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-form solution\n",
    "The closed-form solution is achieved by:\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{W}}=\\frac{2}{n}\\mathbf{X}^T(\\mathbf{X}\\mathbf{W}-\\mathbf{y})=0$$\n",
    "\n",
    "$$\\Leftrightarrow\\mathbf{W}^\\ast=(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Implement the closed-form solution of the weight W.                          #\n",
    "################################################################################\n",
    "\n",
    "A = np.matmul(X_train.T, X_train)\n",
    "B = np.matmul(X_train.T, y_train_oh)\n",
    "W = np.matmul(np.linalg.inv(A), B)\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy:  51.163265306122454\n",
      "Test set accuracy:  36.199999999999996\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy:\n",
    "print('Train set accuracy: ', np.sum(np.argmin(np.abs(1 - X_train.dot(W)), axis=1) == y_train).astype(np.float32)/y_train.shape[0]*100)\n",
    "print('Test set accuracy: ', np.sum(np.argmin(np.abs(1 - X_test.dot(W)), axis=1) == y_test).astype(np.float32)/y_test.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can see that the performance is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "A simple way to improve performance is to include the L2-regularization penalty.\n",
    "$$\\mathcal{L}=\\frac{1}{n}\\|\\mathbf{X}\\mathbf{W}-\\mathbf{y}\\|_F^2 +\\lambda \\|\\mathbf{W}\\|_F^2 \\qquad\\qquad(2)$$\n",
    "The closed-form solution now is: \n",
    "$$\\Leftrightarrow\\mathbf{W}^\\ast=(\\mathbf{X}^T\\mathbf{X}+\\lambda n\\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try several values of lambda to see how it helps:\n",
    "lambdas = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "train_acc = np.zeros((len(lambdas)))\n",
    "test_acc = np.zeros((len(lambdas)))\n",
    "for i in range(len(lambdas)):\n",
    "    l = lambdas[i]\n",
    "    n,d = X_train.shape[0], X_train.shape[1]\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Implement the closed-form solution of the weight W with regularization.      #\n",
    "    ################################################################################\n",
    "    \n",
    "    A = np.matmul(X_train.T, X_train) + (l * n * np.identity(d))\n",
    "    B = np.matmul(X_train.T, y_train_oh)\n",
    "    W = np.matmul(np.linalg.inv(A), B)\n",
    "    \n",
    "    ################################################################################\n",
    "    #                              END OF YOUR CODE                                #\n",
    "    ################################################################################\n",
    "    train_acc[i] = np.sum(np.argmin(np.abs(1 - X_train.dot(W)), axis=1) == y_train).astype(np.float32)/y_train.shape[0]*100\n",
    "    test_acc[i]  = np.sum(np.argmin(np.abs(1 - X_test.dot(W)), axis=1) == y_test).astype(np.float32)/y_test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(lambdas, train_acc, 'r', label=\"Training accuracy\")\n",
    "plt.semilogx(lambdas, test_acc, 'g', label=\"Testing accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Try to explain why the performances on the training and test set have such behaviors as we change the value of $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**  \n",
    "The purpose of have a $\\lambda$ parameter is to introduce the idea of regularization to solve the problem of overfitting.\n",
    "\n",
    "Overfitting refers to the phenomenon where our model performs very well with the training dataset but experiences poor results with the testing dataset. With regularization, we put more pressure on the number of weight parameters. Therefore, by penalising the number of weight parameters, the loss function output value will increase as the number of weight parameters increase.\n",
    "\n",
    "Thus, at small values of $\\lambda$, we will see a high training accuracy since we can have a large number of weight parameters that helps to fit the model closely to the training data. However, overfitting will occur, hence we observe poor testing accuracy at this value of $\\lambda$.\n",
    "\n",
    "At larger values of $\\lambda$, we will see that training accuracy starts to drop, since we reduce the number of weight parameters to minimise the loss function. This means that our model will no longer be as closely fitted to the training data at before. This will also cause the testing accuracy to increase since our model will be able to generalise data better with lesser weight parameters. \n",
    "\n",
    "When the value of $\\lambda$ grows too large, both training and testing accuracies will suffer, as there are too little weight parameters and the model cannot generalise data well anymore. In our case, we see that once the value of $\\lambda$ increases beyond 10^3, both training and testing accuracies starts to dip instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "The predicted probability for the $j$-th class given a sample vector $x$ and a weight $W$ is:\n",
    "\n",
    "$$\\displaystyle{P(y=j\\mid x)=\\frac{e^{-xw_j}}{\\sum\\limits_{c=1}^{C}e^{-xw_c}}}$$ \n",
    "\n",
    "![softmax](imgs/softmax.png \"Example of Softmax\")\n",
    "\n",
    "Your code for this section will all be written inside **classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.337964\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do we expect our loss to be close to -log(0.1)? Explain briefly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**  \n",
    "Since we are calculating our loss based on random weights (i.e., we haven't started the \"learning\" process yet), we expect that the initial loss has to be close to -log(0.1) because initially all the classes are equally likely to be chosen. Since CIFAR-10 consists of samples which belong to one of ten classes, the probability of the correct class will be 1/10 = 0.1. The softmax loss is the negative log probability of the correct class, therefore it is -log(0.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "\n",
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in attempt 0 the loss was 2.358189, best 2.358189\n",
      "in attempt 1 the loss was 2.381420, best 2.358189\n",
      "in attempt 2 the loss was 2.335523, best 2.335523\n",
      "in attempt 3 the loss was 2.310783, best 2.310783\n",
      "in attempt 4 the loss was 2.353139, best 2.310783\n",
      "in attempt 5 the loss was 2.392291, best 2.310783\n",
      "in attempt 6 the loss was 2.362636, best 2.310783\n",
      "in attempt 7 the loss was 2.365318, best 2.310783\n",
      "in attempt 8 the loss was 2.416753, best 2.310783\n",
      "in attempt 9 the loss was 2.364832, best 2.310783\n",
      "in attempt 10 the loss was 2.358573, best 2.310783\n",
      "in attempt 11 the loss was 2.353233, best 2.310783\n",
      "in attempt 12 the loss was 2.400715, best 2.310783\n",
      "in attempt 13 the loss was 2.346051, best 2.310783\n",
      "in attempt 14 the loss was 2.364322, best 2.310783\n",
      "in attempt 15 the loss was 2.339410, best 2.310783\n",
      "in attempt 16 the loss was 2.340192, best 2.310783\n",
      "in attempt 17 the loss was 2.363616, best 2.310783\n",
      "in attempt 18 the loss was 2.359163, best 2.310783\n",
      "in attempt 19 the loss was 2.369597, best 2.310783\n",
      "in attempt 20 the loss was 2.388587, best 2.310783\n",
      "in attempt 21 the loss was 2.392862, best 2.310783\n",
      "in attempt 22 the loss was 2.313808, best 2.310783\n",
      "in attempt 23 the loss was 2.423103, best 2.310783\n",
      "in attempt 24 the loss was 2.359853, best 2.310783\n",
      "in attempt 25 the loss was 2.364470, best 2.310783\n",
      "in attempt 26 the loss was 2.374066, best 2.310783\n",
      "in attempt 27 the loss was 2.317560, best 2.310783\n",
      "in attempt 28 the loss was 2.359727, best 2.310783\n",
      "in attempt 29 the loss was 2.388236, best 2.310783\n",
      "in attempt 30 the loss was 2.356464, best 2.310783\n",
      "in attempt 31 the loss was 2.417594, best 2.310783\n",
      "in attempt 32 the loss was 2.373376, best 2.310783\n",
      "in attempt 33 the loss was 2.387114, best 2.310783\n",
      "in attempt 34 the loss was 2.362240, best 2.310783\n",
      "in attempt 35 the loss was 2.331767, best 2.310783\n",
      "in attempt 36 the loss was 2.365536, best 2.310783\n",
      "in attempt 37 the loss was 2.367833, best 2.310783\n",
      "in attempt 38 the loss was 2.278711, best 2.278711\n",
      "in attempt 39 the loss was 2.355449, best 2.278711\n",
      "in attempt 40 the loss was 2.390439, best 2.278711\n",
      "in attempt 41 the loss was 2.357839, best 2.278711\n",
      "in attempt 42 the loss was 2.321468, best 2.278711\n",
      "in attempt 43 the loss was 2.326473, best 2.278711\n",
      "in attempt 44 the loss was 2.364281, best 2.278711\n",
      "in attempt 45 the loss was 2.394717, best 2.278711\n",
      "in attempt 46 the loss was 2.322318, best 2.278711\n",
      "in attempt 47 the loss was 2.400970, best 2.278711\n",
      "in attempt 48 the loss was 2.359326, best 2.278711\n",
      "in attempt 49 the loss was 2.272516, best 2.272516\n",
      "in attempt 50 the loss was 2.310517, best 2.272516\n",
      "in attempt 51 the loss was 2.365610, best 2.272516\n",
      "in attempt 52 the loss was 2.365215, best 2.272516\n",
      "in attempt 53 the loss was 2.381956, best 2.272516\n",
      "in attempt 54 the loss was 2.401309, best 2.272516\n",
      "in attempt 55 the loss was 2.387564, best 2.272516\n",
      "in attempt 56 the loss was 2.322308, best 2.272516\n",
      "in attempt 57 the loss was 2.360626, best 2.272516\n",
      "in attempt 58 the loss was 2.310527, best 2.272516\n",
      "in attempt 59 the loss was 2.383944, best 2.272516\n",
      "in attempt 60 the loss was 2.347391, best 2.272516\n",
      "in attempt 61 the loss was 2.317753, best 2.272516\n",
      "in attempt 62 the loss was 2.330848, best 2.272516\n",
      "in attempt 63 the loss was 2.328584, best 2.272516\n",
      "in attempt 64 the loss was 2.414387, best 2.272516\n",
      "in attempt 65 the loss was 2.307981, best 2.272516\n",
      "in attempt 66 the loss was 2.383025, best 2.272516\n",
      "in attempt 67 the loss was 2.367787, best 2.272516\n",
      "in attempt 68 the loss was 2.326626, best 2.272516\n",
      "in attempt 69 the loss was 2.327702, best 2.272516\n",
      "in attempt 70 the loss was 2.391061, best 2.272516\n",
      "in attempt 71 the loss was 2.384977, best 2.272516\n",
      "in attempt 72 the loss was 2.351067, best 2.272516\n",
      "in attempt 73 the loss was 2.345127, best 2.272516\n",
      "in attempt 74 the loss was 2.384248, best 2.272516\n",
      "in attempt 75 the loss was 2.400660, best 2.272516\n",
      "in attempt 76 the loss was 2.330432, best 2.272516\n",
      "in attempt 77 the loss was 2.344338, best 2.272516\n",
      "in attempt 78 the loss was 2.330186, best 2.272516\n",
      "in attempt 79 the loss was 2.314007, best 2.272516\n",
      "in attempt 80 the loss was 2.366572, best 2.272516\n",
      "in attempt 81 the loss was 2.377288, best 2.272516\n",
      "in attempt 82 the loss was 2.343578, best 2.272516\n",
      "in attempt 83 the loss was 2.346955, best 2.272516\n",
      "in attempt 84 the loss was 2.425035, best 2.272516\n",
      "in attempt 85 the loss was 2.326370, best 2.272516\n",
      "in attempt 86 the loss was 2.423469, best 2.272516\n",
      "in attempt 87 the loss was 2.342048, best 2.272516\n",
      "in attempt 88 the loss was 2.411416, best 2.272516\n",
      "in attempt 89 the loss was 2.389891, best 2.272516\n",
      "in attempt 90 the loss was 2.319877, best 2.272516\n",
      "in attempt 91 the loss was 2.385751, best 2.272516\n",
      "in attempt 92 the loss was 2.341823, best 2.272516\n",
      "in attempt 93 the loss was 2.425128, best 2.272516\n",
      "in attempt 94 the loss was 2.384023, best 2.272516\n",
      "in attempt 95 the loss was 2.351891, best 2.272516\n",
      "in attempt 96 the loss was 2.343007, best 2.272516\n",
      "in attempt 97 the loss was 2.313557, best 2.272516\n",
      "in attempt 98 the loss was 2.326912, best 2.272516\n",
      "in attempt 99 the loss was 2.345184, best 2.272516\n"
     ]
    }
   ],
   "source": [
    "bestloss = float('inf')\n",
    "for num in range(100):\n",
    "    W = np.random.randn(3073, 10) * 0.0001\n",
    "    loss, _ = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "    if (loss < bestloss):\n",
    "        bestloss = loss\n",
    "        bestW = W\n",
    "    print('in attempt %d the loss was %f, best %f' % (num, loss, bestloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0.132959\n",
      "Accuracy on test set 0.158000\n"
     ]
    }
   ],
   "source": [
    "# How bestW perform on trainset\n",
    "scores = X_train.dot(bestW)\n",
    "y_pred = np.argmax(scores, axis=1)\n",
    "print('Accuracy on train set %f' % np.mean(y_pred == y_train))\n",
    "\n",
    "# evaluate performance of test set\n",
    "scores = X_test.dot(bestW)\n",
    "y_pred = np.argmax(scores, axis=1)\n",
    "print('Accuracy on test set %f' % np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance when using random search with *regression classifier* and *softmax classifier*. You can see how much useful the softmax classifier is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient descent\n",
    "Even though it is possible to achieve closed-form solution with softmax classifier, it would be more complicated. In fact, we could achieve very good results with gradient descent approach. Additionally, in case of very large dataset, it is impossible to load the whole dataset into the memory. Gradient descent can help to optimize the loss function in batch. \n",
    "\n",
    "$$\\mathbf{W}^{t+1}=\\mathbf{W}^{t}−\\alpha \\frac{\\partial\\mathcal{L(\\mathbf{x};\\mathbf{W}^{t})}}{\\partial\\mathbf{W}^{t}}$$\n",
    "\n",
    "Where $\\alpha$ is the learning rate, $\\mathcal{L}$ is a loss function, and $\\mathbf{x}$ is a batch of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -1.268520 analytic: -1.268520, relative error: 2.673774e-09\n",
      "numerical: -1.498243 analytic: -1.498243, relative error: 4.546300e-09\n",
      "numerical: -1.091292 analytic: -1.091292, relative error: 2.083992e-08\n",
      "numerical: -1.282992 analytic: -1.282992, relative error: 2.987137e-08\n",
      "numerical: -2.215568 analytic: -2.215568, relative error: 9.756394e-09\n",
      "numerical: -2.071038 analytic: -2.071038, relative error: 1.663883e-08\n",
      "numerical: 2.138951 analytic: 2.138951, relative error: 2.953210e-08\n",
      "numerical: -6.087443 analytic: -6.087443, relative error: 2.667196e-09\n",
      "numerical: 1.951866 analytic: 1.951866, relative error: 9.234415e-09\n",
      "numerical: 2.643592 analytic: 2.643592, relative error: 8.611758e-09\n",
      "numerical: 3.104153 analytic: 3.104153, relative error: 1.037942e-09\n",
      "numerical: -3.464932 analytic: -3.464933, relative error: 2.571873e-08\n",
      "numerical: 1.950068 analytic: 1.950068, relative error: 4.875809e-09\n",
      "numerical: 3.118712 analytic: 3.118712, relative error: 3.211463e-08\n",
      "numerical: -0.523393 analytic: -0.523393, relative error: 1.889307e-08\n",
      "numerical: -0.842392 analytic: -0.842392, relative error: 1.106036e-07\n",
      "numerical: 0.510743 analytic: 0.510743, relative error: 1.861022e-08\n",
      "numerical: 2.391333 analytic: 2.391333, relative error: 3.636120e-08\n",
      "numerical: 1.400442 analytic: 1.400442, relative error: 2.312027e-08\n",
      "numerical: -0.925175 analytic: -0.925175, relative error: 4.953093e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# Use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.345184e+00 computed in 0.084995s\n",
      "vectorized loss: 2.345184e+00 computed in 0.004003s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# We use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 779.794758\n",
      "iteration 100 / 1500: loss 285.888821\n",
      "iteration 200 / 1500: loss 106.043107\n",
      "iteration 300 / 1500: loss 40.132818\n",
      "iteration 400 / 1500: loss 16.034196\n",
      "iteration 500 / 1500: loss 7.201730\n",
      "iteration 600 / 1500: loss 3.971111\n",
      "iteration 700 / 1500: loss 2.785901\n",
      "iteration 800 / 1500: loss 2.359809\n",
      "iteration 900 / 1500: loss 2.182554\n",
      "iteration 1000 / 1500: loss 2.132032\n",
      "iteration 1100 / 1500: loss 2.117795\n",
      "iteration 1200 / 1500: loss 2.118989\n",
      "iteration 1300 / 1500: loss 2.062584\n",
      "iteration 1400 / 1500: loss 2.073079\n",
      "That took 4.501000s\n"
     ]
    }
   ],
   "source": [
    "from classifiers.linear_classifier import *\n",
    "\n",
    "classifier = Softmax()\n",
    "tic = time.time()\n",
    "loss_hist = classifier.train(X_train, y_train, learning_rate=1e-7, reg=5e4,\n",
    "                                  num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.334000\n",
      "validation accuracy: 0.353000\n"
     ]
    }
   ],
   "source": [
    "# Write the Softmax.predict function and evaluate the performance on both the\n",
    "# training and validation set\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHgCAYAAAAL2HHvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6cklEQVR4nO3deZxdd33f/9fnzq6ZkUYajRZLshZblrENNkJ4AWNSjMGQBLkNJaQkOK0bp4UmJaQhpv39mqbJ7/cgzUKhTU0JJDGUsMRAMITNcbAhEBtLxpZ3W5JlS7IljfZ91m//uGekK1nLzOieOTP3vp6Pxzzu2e69n3vmaO5b3+853xMpJSRJklScUtEFSJIk1TsDmSRJUsEMZJIkSQUzkEmSJBXMQCZJklQwA5kkSVLBGosu4FzMnj07LVmypOgyJEmSzmrt2rU7U0o9p1o3pQPZkiVLWLNmTdFlSJIknVVEPH+6dXZZSpIkFcxAJkmSVDADmSRJUsEMZJIkSQXLNZBFxG9ExOMR8VhEfD4iWiNiaUQ8EBHrI+KLEdGcbduSza/P1i/JszZJkqTJIrdAFhELgF8HVqWULgMagHcDfwB8NKV0IbAHuCV7yi3Anmz5R7PtJEmSal7eXZaNQFtENALTgJeANwF3ZuvvAG7Kpldn82Trr4+IyLk+SZKkwuUWyFJKW4E/Al6gHMT2AWuBvSmlwWyzLcCCbHoBsDl77mC2fffJrxsRt0bEmohY09vbm1f5kiRJEybPLsuZlFu9lgLnAe3Ajef6uimlT6aUVqWUVvX0nHKwW0mSpCklzy7LNwPPpZR6U0oDwFeA1wNdWRcmwEJgaza9FVgEkK2fAezKsT5JkqRJIc9A9gJwdURMy84Fux54Avge8M5sm5uBr2XTd2XzZOv/PqWUcqxPkiRpUsjzHLIHKJ+c/xDwaPZenwR+G/hgRKynfI7Yp7OnfBrozpZ/ELgtr9okSZImk5jKjVCrVq1K3lxckiRNBRGxNqW06lTrHKlfkiSpYAYySZKkghnIJEmSCmYgO4Ph4cSeQ/0MDg0XXYokSaphBrIz+NZj23j1793Nht5DRZciSZJqmIHsDLo7mgHYdbCv4EokSVItM5CdwewskO081F9wJZIkqZYZyM6gu70FsIVMkiTly0B2BjPammgoBbsO2kImSZLyYyA7g1IpmNXezK5DtpBJkqT8GMjOoru9mZ22kEmSpBwZyM6iu6PZc8gkSVKuDGRn0d3ewi6vspQkSTkykJ1Fd0czu+2ylCRJOTKQncXsjhYO9A1ydGCo6FIkSVKNMpCdRXd7eXDY3XZbSpKknBjIzmJW+8jtkwxkkiQpHways+juKI/Wv9OxyCRJUk4MZGcxu8MWMkmSlC8D2VmMtJA5FpkkScqLgews2psbaGksORaZJEnKjYHsLCKC2R0t7LSFTJIk5cRANgrl2yfZQiZJkvJhIBuFWe3N7PIqS0mSlBMD2Sh0t7ew84AtZJIkKR8GslHo6Wxh16E+UkpFlyJJkmqQgWwUejpbGBhK7DsyUHQpkiSpBhnIRqGnszwWWe8BzyOTJEnVZyAbhZ4OA5kkScqPgWwUjrWQORaZJEnKgYFsFOyylCRJeTKQjcL01kaaG0sGMkmSlAsD2ShEBD0dLQYySZKUCwPZKPV0tngOmSRJyoWBbJR6Om0hkyRJ+TCQjZKBTJIk5cVANko9HS3sPtzPwNBw0aVIkqQaYyAbpZ7OFlKC3Ye8ybgkSaouA9kozXa0fkmSlBMD2Sg5Wr8kScqLgWyU5jhavyRJyomBbJTsspQkSXnJLZBFxIqIeLjiZ39EfCAiZkXE3RHxbPY4M9s+IuLjEbE+ItZFxMq8ahuPtuYGOlsaDWSSJKnqcgtkKaWnU0pXpJSuAF4DHAa+CtwG3JNSWg7ck80DvA1Ynv3cCtyeV23j5Wj9kiQpDxPVZXk9sCGl9DywGrgjW34HcFM2vRr4TCq7H+iKiPkTVN+ozHZwWEmSlIOJCmTvBj6fTc9NKb2UTW8D5mbTC4DNFc/Zki07QUTcGhFrImJNb29vXvWeUk9nCzsNZJIkqcpyD2QR0Qy8A/jrk9ellBKQxvJ6KaVPppRWpZRW9fT0VKnK0enpsIVMkiRV30S0kL0NeCiltD2b3z7SFZk97siWbwUWVTxvYbZs0ujpbOFA3yBH+oeKLkWSJNWQiQhkv8Dx7kqAu4Cbs+mbga9VLH9vdrXl1cC+iq7NSWFkcNidntgvSZKqKNdAFhHtwA3AVyoWfwS4ISKeBd6czQN8E9gIrAf+DHhfnrWNx0gg22G3pSRJqqLGPF88pXQI6D5p2S7KV12evG0C3p9nPeeqx8FhJUlSDhypfwzmeD9LSZKUAwPZGMxqbyYCh76QJElVZSAbg8aGEt3tzbaQSZKkqjKQjdFsxyKTJElVZiAbox5vnyRJkqrMQDZGBjJJklRtBrIxGglk5VE6JEmSzp2BbIzmdrbSPzTMnsMDRZciSZJqhIFsjObNaAVg+/6jBVciSZJqhYFsjOZOLw8OayCTJEnVYiAbozmd5RayHfs9sV+SJFWHgWyM5mQtZNtsIZMkSVViIBujlsYGZrU322UpSZKqxkA2DnM6W9hul6UkSaoSA9k4zJ3eyo4DtpBJkqTqMJCNw9zpLWzbZyCTJEnVYSAbh3nTW9l5sI/BoeGiS5EkSTXAQDYOc6a3Mpxg16H+okuRJEk1wEA2DnOnO1q/JEmqHgPZOIyM1u95ZJIkqRoMZOMwb6SF7IBDX0iSpHNnIBuH7o4WSgE77LKUJElVYCAbh4ZS0NPp0BeSJKk6DGTjNHd6q12WkiSpKgxk4zR3eqtdlpIkqSoMZOM0d3qLw15IkqSqMJCN09zOVvYcHuDowFDRpUiSpCnOQDZOI4PD9noemSRJOkcGsnGaO8PR+iVJUnUYyMZpZLT+7fttIZMkSefGQDZOczvLLWTbbCGTJEnnyEA2Tl3TmmhuLDn0hSRJOmcGsnGKCIe+kCRJVWEgOwdzO1s9h0ySJJ0zA9k5mDu91RYySZJ0zgxk52DO9Ba27T9KSqnoUiRJ0hRmIDsH82e0crh/iAN9g0WXIkmSpjAD2TmYN6MNgG377LaUJEnjZyA7B+dlo/W/ZCCTJEnnwEB2DuZlgWzbviMFVyJJkqYyA9k5mNPZSgS8uNcWMkmSNH65BrKI6IqIOyPiqYh4MiKuiYhZEXF3RDybPc7Mto2I+HhErI+IdRGxMs/aqqG5scTsjhbPIZMkSeck7xayjwHfTildDFwOPAncBtyTUloO3JPNA7wNWJ793ArcnnNtVXHejFZeciwySZJ0DnILZBExA7gO+DRASqk/pbQXWA3ckW12B3BTNr0a+Ewqux/oioj5edVXLfNmtHoOmSRJOid5tpAtBXqBv4iIn0TEpyKiHZibUnop22YbMDebXgBsrnj+lmzZpDZ/RptXWUqSpHOSZyBrBFYCt6eUXg0c4nj3JACpPMT9mIa5j4hbI2JNRKzp7e2tWrHjNW9GKweODnLQwWElSdI45RnItgBbUkoPZPN3Ug5o20e6IrPHHdn6rcCiiucvzJadIKX0yZTSqpTSqp6entyKH635Dn0hSZLOUW6BLKW0DdgcESuyRdcDTwB3ATdny24GvpZN3wW8N7va8mpgX0XX5qQ1Pxut325LSZI0Xo05v/6vAZ+LiGZgI/AvKYfAL0XELcDzwLuybb8JvB1YDxzOtp305jtavyRJOke5BrKU0sPAqlOsuv4U2ybg/XnWk4c501sAeMnBYSVJ0jg5Uv85amlsKA8Ou99zyCRJ0vgYyKpg/oxWuywlSdK4GciqoDw4rIFMkiSNj4GsCmwhkyRJ58JAVgXzZ7Sx78iAg8NKkqRxMZBVwYKZ2Vhkez2xX5IkjZ2BrAoWdJXHIttiIJMkSeNgIKuCBV3TAHjRQCZJksbBQFYFPZ0tNJaCrXsMZJIkaewMZFXQUArmd7XaQiZJksbFQFYl581oY6uBTJIkjYOBrEoWzGzjRe9nKUmSxsFAViULutrYtv8og0PDRZciSZKmGANZlSzoamNoOLH9QF/RpUiSpCnGQFYl53WVB4f1SktJkjRWBrIqGRmtf+vewwVXIkmSphoDWZWcN6McyDyxX5IkjZWBrEramhvobm9mi12WkiRpjAxkVXReV5uDw0qSpDEzkFXRgi4Hh5UkSWNnIKuikRaylFLRpUiSpCnEQFZFC2a2cbh/iL2HB4ouRZIkTSEGsipa0NUKYLelJEkaEwNZFS3omgYYyCRJ0tgYyKrovKyFzCstJUnSWBjIqmhWezOtTSVvnyRJksbEQFZFEVG+0nKfgUySJI2egazKFnS12UImSZLGxEBWZeXBYb2fpSRJGj0DWZUt6Gpj58E+jg4MFV2KJEmaIgxkVbZwVhvg0BeSJGn0DGRVtmhmeSyyzbsPF1yJJEmaKgxkVbZwJJB5Yr8kSRolA1mVzelsobmxxBZbyCRJ0igZyKqsVAoWdrWxeY+BTJIkjY6BLAcLZ01j8267LCVJ0ugYyHKwaGYbW2whkyRJo2Qgy8GiWdPYc3iAg32DRZciSZKmAANZDhbOLI9F5tAXkiRpNAxkOXAsMkmSNBYGshwsmuVYZJIkafQMZDmYOa2J9uYGT+yXJEmjkmsgi4hNEfFoRDwcEWuyZbMi4u6IeDZ7nJktj4j4eESsj4h1EbEyz9ryFBEscugLSZI0ShPRQvZPUkpXpJRWZfO3AfeklJYD92TzAG8Dlmc/twK3T0BtuVk4c5otZJIkaVSK6LJcDdyRTd8B3FSx/DOp7H6gKyLmF1BfVSyc2cbm3YdJKRVdiiRJmuTyDmQJ+G5ErI2IW7Nlc1NKL2XT24C52fQCYHPFc7dky6ak82dN41D/EHsODxRdiiRJmuQac379a1NKWyNiDnB3RDxVuTKllCJiTE1IWbC7FeD888+vXqVVtri7fKXl87sOMau9ueBqJEnSZJZrC1lKaWv2uAP4KnAlsH2kKzJ73JFtvhVYVPH0hdmyk1/zkymlVSmlVT09PXmWf06OBzLPI5MkSWeWWyCLiPaI6ByZBt4CPAbcBdycbXYz8LVs+i7gvdnVllcD+yq6NqechTOnEWEgkyRJZ5dnl+Vc4KsRMfI+f5VS+nZEPAh8KSJuAZ4H3pVt/03g7cB64DDwL3OsLXetTQ3Mn97K87sOFV2KJEma5HILZCmljcDlp1i+C7j+FMsT8P686inC4u52nvf2SZIk6SwcqT9Hi7un2UImSZLOykCWo8Xd7ew82M/BvsGiS5EkSZOYgSxHlUNfSJIknY6BLEcjgewFr7SUJElnYCDL0eLudgA2GcgkSdIZGMhy1NHSyOyOZl7YbZelJEk6PQNZzs6fNY1NO20hkyRJp2cgy9mS7nZecCwySZJ0BgaynJ3fPY0X9x2hb3Co6FIkSdIkZSDL2ZLudlKCzbuPFF2KJEmapAxkOTvfscgkSdJZGMhytnjWSCDzPDJJknRqBrKczWpvprOl0RYySZJ0WgaynEUE53dPc3BYSZJ0WgayCeDQF5Ik6UwMZBPg/O5pbN59mMGh4aJLkSRJk5CBbAIs6Z7G4HDixb1Hiy5FkiRNQgayCbB0dgcAG3ceLLgSSZI0GRnIJsCynnYANvZ6paUkSXo5A9kE6G5vZnproy1kkiTplAxkEyAiWNbTYQuZJEk6JQPZBFk2u91AJkmSTslANkGW9bSzbf9RDvUNFl2KJEmaZAxkE2RZT/lKy+d22komSZJOZCCbIMeutDSQSZKkkxjIJsiS7nYiYGOvV1pKkqQTnTWQRcTciPh0RHwrm78kIm7Jv7Ta0trUwIKuNk/slyRJLzOaFrK/BL4DnJfNPwN8IKd6atrS2e2ORSZJkl5mNIFsdkrpS8AwQEppEBjKtaoadUFPB8/1HiKlVHQpkiRpEhlNIDsUEd1AAoiIq4F9uVZVo5b1tHOof4jt+/uKLkWSJE0ijaPY5oPAXcAFEfFDoAd4Z65V1ahlIzcZ7z3IvBmtBVcjSZImi7MGspTSQxHxRmAFEMDTKaWB3CurQZVDX7zuwtkFVyNJkiaLswayiHjvSYtWRgQppc/kVFPNmje9ldamkldaSpKkE4ymy/K1FdOtwPXAQ4CBbIxKpWDp7A6vtJQkSScYTZflr1XOR0QX8IW8Cqp1y3raWbdlb9FlSJKkSWQ8I/UfApZWu5B6cWFPB1v2HOHogCOHSJKkstGcQ/Z1siEvKAe4S4Av5VlULVs+t4OUYEPvQS49b0bR5UiSpElgNOeQ/VHF9CDwfEppS0711LwL55SHvli/w0AmSZLKRnMO2X0TUUi9WDq7nVLAhh2e2C9JkspOG8gi4gDHuypPWAWklNL03KqqYS2NDSzubmd9r4FMkiSVnTaQpZQ6J7KQenJBTwfPbjeQSZKkslFfZRkRcyLi/JGfPIuqdRfO6WDTrkMMDg0XXYokSZoEzhrIIuIdEfEs8BxwH7AJ+NZo3yAiGiLiJxHxjWx+aUQ8EBHrI+KLEdGcLW/J5tdn65eM5wNNBcvndDAwlHh+9+GiS5EkSZPAaFrIfg+4GngmpbSU8kj994/hPf498GTF/B8AH00pXQjsAW7Jlt8C7MmWfzTbriZVXmkpSZI0mkA2kFLaBZQiopRS+h6wajQvHhELgZ8GPpXNB/Am4M5skzuAm7Lp1dk82frrs+1rzgUGMkmSVGE045DtjYgO4PvA5yJiB+XR+kfjvwMfAkYuEOgG9qaUBrP5LcCCbHoBsBkgpTQYEfuy7XeO8r2mjI6WRhZ0tfHM9gNFlyJJkiaB0bSQrQYOA78BfBvYAPzs2Z4UET8D7EgprT2nCl/+urdGxJqIWNPb21vNl55QK+Z18tRLBjJJkjS6QParwPyU0mBK6Y6U0sezLsyzeT3wjojYRPlm5G8CPgZ0RcRIy9xCYGs2vRVYBJCtnwG87H1SSp9MKa1KKa3q6ekZRRmT04p5nWzoPUj/oFdaSpJU70YTyDqB70bEDyLi30XE3NG8cErpwymlhSmlJcC7gb9PKb0H+B7wzmyzm4GvZdN3ZfNk6/8+pXSqgWlrwsXzOhkcTmzc6XlkkiTVu7MGspTS76aULgXeD8wH7ouIvzuH9/xt4IMRsZ7yOWKfzpZ/GujOln8QuO0c3mPSu3he+UYHT2+z21KSpHo3mpP6R+wAtlHuRpwzljdJKd0L3JtNbwSuPMU2R4F/PpbXncqW9bTT1BA8te0Aq4suRpIkFWo0A8O+LyLuBe6h3KL1KymlV+VdWK1raihxQU+HLWSSJGlULWSLgA+klB7OuZa6s2JeJ2s27Sm6DEmSVLDRnEP2YcNYPlbM62Tr3iPsPzpQdCmSJKlAo765uKrv4nnl8XKfsdtSkqS6ZiAr0IrsSssnDWSSJNW10ZzU3x4RpWz6ooh4R0Q05V9a7TtvRiudrY08vW1/0aVIkqQCjaaF7PtAa0QsAL4L/BLwl3kWVS8ighVzO73SUpKkOjeaQBYppcPAPwP+V0rpnwOX5ltW/Vgxr5Onth2ghm9KIEmSzmJUgSwirgHeA/xttqwhv5Lqy8XzOjlwdJCX9h0tuhRJklSQ0QSyDwAfBr6aUno8IpZRvh+lqmCFt1CSJKnunXVg2JTSfcB9ANnJ/TtTSr+ed2H1YsXc8tAXT207wD+5eEx3pJIkSTViNFdZ/lVETI+IduAx4ImI+K38S6sPM6Y1MX9Gq1daSpJUx0bTZXlJSmk/cBPwLWAp5SstVSUjJ/ZLkqT6NJpA1pSNO3YTcFdKaQDwksAqunjedDb0HmRgaLjoUiRJUgFGE8j+N7AJaAe+HxGLAfvXqujieZ0MDCU29h4quhRJklSA0dxc/OMppQUppbensueBfzIBtdWNFfNGTuw350qSVI9Gc1L/jIj4k4hYk/38MeXWMlXJBT0dNJbCoS8kSapTo+my/HPgAPCu7Gc/8Bd5FlVvmhtLLOtpN5BJklSnzjoOGXBBSunnKuZ/NyIezqmeurVi3nQeen5P0WVIkqQCjKaF7EhEXDsyExGvB47kV1J9umT+dLbuPcLew/1FlyJJkibYaFrI/g3wmYiYkc3vAW7Or6T69MoF5d372Nb9XLt8dsHVSJKkiTSaqywfSSldDrwKeFVK6dXAm3KvrM5cel75npaPvbiv4EokSdJEG02XJQAppf3ZiP0AH8ypnro1s72ZBV1tPLbVQCZJUr0ZdSA7SVS1CgHlbksDmSRJ9We8gcxbJ+XgsgXT2bTrMPuPDhRdiiRJmkCnPak/Ig5w6uAVQFtuFdWxy7IT+x/fup9rLuguuBpJkjRRTttCllLqTClNP8VPZ0ppNFdnaoyOBTJP7Jckqa6Mt8tSOZjd0cL8Ga2eRyZJUp0xkE0yl543g0cNZJIk1RUD2STzygUz2LjzEIf6BosuRZIkTRAD2SRz2YLppARPvrT/7BtLkqSaYCCbZEZO7LfbUpKk+mEgm2TmTm+lp7PFQCZJUh0xkE1Cly+cwbotBjJJkuqFgWwSunxhFxt6DzpivyRJdcJANgldvqiLlOAxW8kkSaoLBrJJ6FULyyf2P7xlb7GFSJKkCWEgm4S6pjWzpHsaj2zeW3QpkiRpAhjIJqnLF3XxyGa7LCVJqgcGsknqikVdbNt/lJf2HSm6FEmSlDMD2SS18vyZADz0/N5iC5EkSbkzkE1Sr5g/nZbGEg+9sKfoUiRJUs5yC2QR0RoRP46IRyLi8Yj43Wz50oh4ICLWR8QXI6I5W96Sza/P1i/Jq7apoLmxxKsWzjCQSZJUB/JsIesD3pRSuhy4ArgxIq4G/gD4aErpQmAPcEu2/S3Anmz5R7Pt6trK82fy+Nb99A0OFV2KJEnKUW6BLJUdzGabsp8EvAm4M1t+B3BTNr06mydbf31ERF71TQWvPn8m/UPDPLZ1f9GlSJKkHOV6DllENETEw8AO4G5gA7A3pTSYbbIFWJBNLwA2A2Tr9wHdedY32a1c3AXAT+y2lCSppuUayFJKQymlK4CFwJXAxef6mhFxa0SsiYg1vb295/pyk9qczlYWzmzzPDJJkmrchFxlmVLaC3wPuAboiojGbNVCYGs2vRVYBJCtnwHsOsVrfTKltCqltKqnpyfv0gu38vyZrH1+DymlokuRJEk5yfMqy56I6Mqm24AbgCcpB7N3ZpvdDHwtm74rmydb//fJFMLK87vYvr+PF/cdLboUSZKUk8azbzJu84E7IqKBcvD7UkrpGxHxBPCFiPh94CfAp7PtPw18NiLWA7uBd+dY25SxcvHIALF7WNDVVnA1kiQpD7kFspTSOuDVp1i+kfL5ZCcvPwr887zqmapeMX86rU3lAWJ/9vLzii5HkiTlwJH6J7mmhhKvWtDFQy/sLboUSZKUEwPZFPDqxV088eI+jg44QKwkSbXIQDYFvOb8mQwMJR7buq/oUiRJUg4MZFPAyIn9D25yPDJJkmqRgWwKmN3RwgU97Tzw3MuGZZMkSTXAQDZFXLWsmzWb9jA0XPdDs0mSVHMMZFPEVUtncbBvkCde9EbjkiTVGgPZFHHV0vJ91u22lCSp9hjIpoh5M1pZ3D2N+zfuLroUSZJUZQayKeSqpbN4cNNuhj2PTJKkmmIgm0KuWtrNviMDPLXtQNGlSJKkKjKQTSFXLZsFwI89j0ySpJpiIJtCFs6cxoKuNh54zvPIJEmqJQayKeaqpbP48XO7ScnzyCRJqhUGsinm6gu62XWo3/PIJEmqIQayKeYNy2cD8P1neguuRJIkVYuBbIqZP6ONFXM7+f6zBjJJkmqFgWwKuu6i2Tz43B4O9w8WXYokSaoCA9kU9MaL5tA/NMz9Gx3+QpKkWmAgm4JWLZlJa1OJ+56221KSpFpgIJuCWpsauGZZN99/dmfRpUiSpCowkE1R113Uw3M7D/HCrsNFlyJJks6RgWyKuu6iHgDu82pLSZKmPAPZFLVsdjsLZ7Y5HpkkSTXAQDZFRQTXXdTDP27YRf/gcNHlSJKkc2Agm8LeeFEPB/sGeeiFPUWXIkmSzoGBbAp73QXdNJbCbktJkqY4A9kU1tnaxMrzZ3obJUmSpjgD2RT3xhU9PLZ1P70H+oouRZIkjZOBbIq7bnl5+It/WG8rmSRJU5WBbIq79LzpdLc3exslSZKmMAPZFFcqBW9YPpsfPLuT4eFUdDmSJGkcDGQ14LqLeth1qJ8nXtpfdCmSJGkcDGQ14A3ZeWT3OfyFJElTkoGsBvR0tnDpedM9j0ySpCnKQFYj3nTxHNa+sIc9h/qLLkWSJI2RgaxGvPkVcxkaTtz7zI6iS5EkSWNkIKsRr1wwg7nTW7j7ie1FlyJJksbIQFYjSqXg+lfM5b6ne+kbHCq6HEmSNAYGshpywyVzOdQ/xA/X7yy6FEmSNAYGshry+gtmM721kb9dt63oUiRJ0hgYyGpIc2OJGy6Zx91PbKN/cLjociRJ0ijlFsgiYlFEfC8inoiIxyPi32fLZ0XE3RHxbPY4M1seEfHxiFgfEesiYmVetdWyn37VPPYfHbTbUpKkKSTPFrJB4DdTSpcAVwPvj4hLgNuAe1JKy4F7snmAtwHLs59bgdtzrK1mXXthD52tjfztoy8VXYokSRql3AJZSumllNJD2fQB4ElgAbAauCPb7A7gpmx6NfCZVHY/0BUR8/Oqr1aVuy3n8t3H7baUJGmqmJBzyCJiCfBq4AFgbkpppPlmGzA3m14AbK542pZs2cmvdWtErImINb293iroVH76lfPL3ZYb7LaUJGkqyD2QRUQH8GXgAyml/ZXrUkoJSGN5vZTSJ1NKq1JKq3p6eqpYae24dvlsOlsa+eY6uy0lSZoKcg1kEdFEOYx9LqX0lWzx9pGuyOxx5F4/W4FFFU9fmC3TGLU0NpS7LZ/YzsCQ3ZaSJE12eV5lGcCngSdTSn9Sseou4OZs+mbgaxXL35tdbXk1sK+ia1Nj9PZXzmffkQGvtpQkaQrIs4Xs9cAvAW+KiIezn7cDHwFuiIhngTdn8wDfBDYC64E/A96XY2017w0Xlbstv/6ImVaSpMmuMa8XTin9AxCnWX39KbZPwPvzqqfetDQ28NOvms9dj7zIf119Ke0tuf2qJUnSOXKk/hr2c69ZyOH+Ib79mLdSkiRpMjOQ1bBVi2dy/qxpfOUnW4ouRZIknYGBrIZFBP9s5QJ+tGEXL+49UnQ5kiTpNAxkNe7nVi4kJfjqTxxBRJKkycpAVuMWzZrGlUtn8eW1WyhfNyFJkiYbA1kdeOfKhWzceYifbN5bdCmSJOkUDGR14G2vnEdrU4kvr/XkfkmSJiMDWR3obG3irZfO4+uPvEjf4FDR5UiSpJMYyOrEz61cyP6jg9zz5I6zbyxJkiaUgaxOvP7C2cyb3soXHtxcdCmSJOkkBrI60VAKfuHK8/n+M708t/NQ0eVIkqQKBrI68gtXLaKpIfjsPz5fdCmSJKmCgayOzOls5cbL5vPXazdzuH+w6HIkSVLGQFZnbr5mMQeODvI3P3mx6FIkSVLGQFZnXrN4JpfMn85n/nGTI/dLkjRJGMjqTETw3msW89S2Azy4aU/R5UiSJAxkdWn1FQuY3trIHf+4qehSJEkSBrK61NbcwLtWLeI7j21j+/6jRZcjSVLdM5DVqV+8ejFDKfFXD7xQdCmSJNU9A1mdWjK7nZ+6qIe/+vEL9A8OF12OJEl1zUBWx957zRJ6D/TxrcdeKroUSZLqmoGsjr3xoh4unNPB7fducAgMSZIKZCCrY6VS8G/eeAFPbTvAvU/3Fl2OJEl1y0BW595x+XmcN6OV2+/dUHQpkiTVLQNZnWtuLPEr1y3jx5t2s2bT7qLLkSSpLhnIxM+/dhEzpzXxp99bX3QpkiTVJQOZmNbcyL9+wzK+93QvD2/eW3Q5kiTVHQOZALj5dUuYOa2Jj/3dM0WXIklS3TGQCYCOlkZ+5bpyK5nnkkmSNLEMZDrml1+3hDmdLXzkW085LpkkSRPIQKZjpjU38oE3X8Sa5/dw9xPbiy5HkqS6YSDTCd61aiHLetr5b995msEh73EpSdJEMJDpBI0NJT701otZv+MgX35oS9HlSJJUFwxkepm3XjqXV5/fxUfvfpYj/UNFlyNJUs0zkOllIoLbbryYbfuP8hc/eq7ociRJqnkGMp3SVcu6uf7iOdx+7wb2HOovuhxJkmqagUyn9aEbL+ZQ36C3VJIkKWcGMp3WinmdvPM1C7njHzexofdg0eVIklSzDGQ6o99668W0NjXwX+563MFiJUnKiYFMZ9TT2cJ/eMsKfvDsTr6+7qWiy5EkqSYZyHRWv3j1Yl61cAa/940n2HdkoOhyJEmqObkFsoj484jYERGPVSybFRF3R8Sz2ePMbHlExMcjYn1ErIuIlXnVpbFrKAX//z99JbsO9vFH33m66HIkSao5ebaQ/SVw40nLbgPuSSktB+7J5gHeBizPfm4Fbs+xLo3DZQtmcPPrlvB/HnieNZt2F12OJEk1JbdAllL6PnDyN/dq4I5s+g7gporln0ll9wNdETE/r9o0Pr/5lhUsnNnGB7/0CIf6BosuR5KkmjHR55DNTSmNnBm+DZibTS8ANldstyVbpkmko6WRP3nXFWzec5jf/9snii5HkqSaUdhJ/ak8hsKYx1GIiFsjYk1ErOnt7c2hMp3Ja5fM4levu4DP/3gz9zy5vehyJEmqCRMdyLaPdEVmjzuy5VuBRRXbLcyWvUxK6ZMppVUppVU9PT25FqtT+40blvOK+dP57S+vY9fBvqLLkSRpypvoQHYXcHM2fTPwtYrl782utrwa2FfRtalJpqWxgf/+81ew/8ggH/7Kow4YK0nSOcpz2IvPA/8IrIiILRFxC/AR4IaIeBZ4czYP8E1gI7Ae+DPgfXnVpepYMa+T33rrCr77xHbuXLul6HIkSZrSGvN64ZTSL5xm1fWn2DYB78+rFuXjlmuX8ndPbud3v/4EVy6dxeLu9qJLkiRpSnKkfo1bqRT88bsup7Eh+JXPrOGgQ2FIkjQuBjKdk4Uzp/G//sVKNvQe4gNfeJjhYc8nkyRprAxkOmevu3A2v/Ozl/B3T27nj+/21kqSJI1VbueQqb780tWLefKlA/zp9zZw0dxOVl/huL6SJI2WLWSqiojgd99xKVcuncWH7lzHui17iy5JkqQpw0CmqmluLHH7e1Yyu6OFWz+zlh37jxZdkiRJU4KBTFXV3dHCp25exf6jA9z62bUcHRgquiRJkiY9A5mq7hXzp/Mn77qChzfv5bfuXMeQV15KknRGBjLl4sbL5vHht13M1x95kQ9/ZZ3DYUiSdAZeZanc/OobL+Bw/xAfu+dZmhtL/N7qy4iIosuSJGnSMZApVx9483L6Bof5xH0baG5o4P/9mVcYyiRJOomBTLmKCH77xhX0DQ7x5z98jpamEh966wpDmSRJFQxkyl1E8J9/5hL6B4e5/d4NAIYySZIqGMg0ISKC31t9GQm4/d4N7D08wO/fdBkNJUOZJEkGMk2YUin4/266jJnTmvjT722g90AfH3v3FbS3eBhKkuqbw15oQkUEv/XWi/mvqy/le0/v4Odu/xFb9x4puixJkgplIFMh3nvNEv7il1/L1r1HWP0//4G1z+8puiRJkgpjIFNhrruoh6++73W0tzTyC392P3/zk61FlyRJUiEMZCrUhXM6+Zv3vZ5XL+riA198mN//xhP0DXr/S0lSfTGQqXAz25v57C1X8d5rFvOpf3iOm/70Rzyz/UDRZUmSNGEMZJoUmhtL/NfVl/Hpm1exY/9RfvZ//AN/+cPnSMl7YEqSap+BTJPK9a+Yy7c/cB2vu6Cb//L1J7j5Lx5kx/6jRZclSVKuDGSadHo6W/jzX34tv7f6Uh7YuIsbP/YDvvv4tqLLkiQpNwYyTUoRwS9ds4S//fVrmT+jlVs/u5Zf/ewaNu8+XHRpkiRVnYFMk9qFczr56vtez2/ecBE/eHYnb/no9/kf9zzL0QGvxJQk1Q4DmSa95sYSv3b9cu7+4Bt540U9/PHdz/BTf3gvX1qzmeFhT/qXJE19BjJNGQu62vjEL72GL956NfNmtPKhO9fxzk/8iB9t2OnVmJKkKc1ApinnqmXdfPV9r+MP3/kqtuw5wr/4swf4+f99Pz9cbzCTJE1NMZW/wFatWpXWrFlTdBkq0NGBIb744GZuv3cD2/Yf5TWLZ3Lrdct48yvm0lCKosuTJOmYiFibUlp1ynUGMtWCowND/PWazXzivo1s3XuEJd3T+FfXLuWdr1nItObGosuTJMlApvoxODTMdx7fzp/9YCMPb97LjLYm3v3aRbz7yvNZOru96PIkSXXMQKa6tPb53XzqB8/x3Se2MzScuGrpLN595SLecsk82ltsNZMkTSwDmera9v1HuXPtFr60ZjPP7zpMa1OJGy+dx+orFvC6C7tpaWwoukRJUh0wkEnA8HDiwU27+fq6F/naT17kQN8gnS2N3HDJXG68bB7XXdRDa5PhTJKUDwOZdJK+wSF+tH4X33z0Jb7z+Db2Hx2kramBa5fP5nUXdHPdRT0sm91OhFdqSpKqw0AmncHA0DAPbNzNdx7fxr3P7GDz7iMALJrVxrUX9nDthbO5cuksejpbCq5UkjSVGcikMdi8+zD3PtPLfU/3cv/GXRzsGwRg+ZwOrl7WzcrFXbxywQyWzu5wrDNJ0qgZyKRxGhwaZt3WfTywcTf3b9zFmk27OdRfvrF5e3MDl543g8sWzODKpTO5fFEX86a32s0pSTolA5lUJYNDw2zoPcSjW/fx6Ja9PLp1H0+8tJ+jA8MAdLY0ctG8Ti6a28mKuR0s6+lg6ex2zutqszVNkuqcgUzK0eDQMGuf38Mz2w/w7I6DPLXtAE9vO8C+IwPHtmluKLG4expLZ7cf+1kyu51ls9vp6WyxVU2S6sCZApmjY0rnqLGhxFXLurlqWfexZSkleg/0sXHnITbtPMRzOw+xMXu89+le+oeGj23b3txAT2cL53W1sXBmG7M7Wso/nS3M7mimJ5vvmtZkcJOkGmUgk3IQEcyZ3sqc6a1cXRHUAIaGEy/uPcJzWUB7buchdh7sY/Puw9z3TC+7DvYzOPzyluvGUtDd0Xw8sHW00DMS2jpbKpY3M3NaMyW7SCVpyphUgSwibgQ+BjQAn0opfaTgkqSqaygFi2ZNY9GsaVx3Uc/L1g8PJ/YdGWDnwT56D/ax82A/vQf62Hmwj50jjwf7eWb7AXYe7GNg6OXhraEUTGtqYFpLA52tTXS0NNLZ2sj01iY6W8vTHS1NtDaVaG1qoGtaEzPammhraqCtuYFpzQ20NjUwrbmRac0NtDSWbJ2TpBxNmkAWEQ3AnwI3AFuAByPirpTSE8VWJk2sUimY2d7MzPZmls/tPOO2KSX2HxnMgltlaOvnUP8gh/oGOXB0kIN9g+w/OsjWvUfK80cHOTIwNOqaIqCtqYGGCFqaSsxoa6KhFDSUSnS2NNJQClqbSrRlQa6tqYHBoURbFuaGsha/topw19JYormxRHND6djnbm4oB8SmhqBUChoiaCgFpeyxoVRufTzV8lLFsqaGEqUSBEFjqfxapShvEyc/cnze0CmpKJMmkAFXAutTShsBIuILwGrAQCadRkQwY1oTM6Y1ceGcjjE9d2BomP7BYY4MDLH38AD7jgzQNzDEkYEhDvcPcaR/iMP9gxwZGOZI/yCH+4cYTnBkYIh9R/oZGk4MDScO9g0yODzMrkODHNlTfu7RgSEi4OjAMANDwzSWgkT5uZP5OqIITgxoZAsoPzSUygEvjq0v/w4iey5ULs+eX/G6I4GvHP7K609+nZHdcywanvzcY+91/PnH6z9eS0ownO3sUgSlUnnZ0HCipbH0sg8+8jIDQ8PHAvTJr3ny+w4MJRpLQWNDnPCcE+rPXr900ucsRTCcEof7h2hsyN7/lJ+x/Jyh4cRwSsd+NyPHUeX+Ktc0TGOpRFNDMJzK/2k5nTMdimc6Ts96CI/1IK/4JTbESccfMHJgDAwPM7Kbj/0H4/QvlT31ZQvONHvC84eGEwNDiaaGONYSX8r+41KqOH4T5fqGUyIB/YPlc2QrfwcJsv8sBUGQSAxnx2P5P1XHj6GUEhHlf2vlGoaPHf+Jyn9fZzbyWzj5WKn8/TRk/55LAb949WJWX7HgLK+an8kUyBYAmyvmtwBXFVSLVPOaGko0NZRob2lkdsfE3IUgpfIf+ESib3CYvoFh+oeGCTj2h/fIwNCxsDecEkPDVEwnhlJi+OT1FcuGUvl1UvZFMDScjp2TN5xS9gWRfXmcZn7ki+X4H/IE2ZfH4HA69gWTUnld+XFk+2y+4rmV60deK8FJr3P8i6hyf4182VW+Fie998gmqXJjyl+A5c9d/kxBuSWyf3D42BfvyHuPvF9zQ+nYEC0nf6bjy8p1NZZKDGf7u6F0/Ku/Mo5UfrbKmodTojHKra1DKb2sjsrPOPJZKr+04cSQOvIeTQ2lY6FypBV0vM7UYnq2Vx3t21Zmt0T5lIXhlF52/EQJOpoajweTlI4F7lO91innOcv2Jy1rLJVobQoGhxKtTeXgMvK+I7/D4cSx46oxC5KtTeWW74GhRKl0PNAPDScGj51ikbVol4Kh4eHsPUrHAmSi/Leipan8N2rks47UcLZ9+rJgWnGswPH/tAwNl/8eDQ8X30I+mQLZqETErcCtAOeff37B1Ugai4igubH8R6+lsQFaCy5IkiaJ0tk3mTBbgUUV8wuzZSdIKX0ypbQqpbSqp+flJ0RLkiRNNZMpkD0ILI+IpRHRDLwbuKvgmiRJknI3abosU0qDEfHvgO9QHvbiz1NKjxdcliRJUu4mTSADSCl9E/hm0XVIkiRNpMnUZSlJklSXDGSSJEkFM5BJkiQVzEAmSZJUMAOZJElSwQxkkiRJBTOQSZIkFcxAJkmSVDADmSRJUsEMZJIkSQUzkEmSJBXMQCZJklQwA5kkSVLBDGSSJEkFi5RS0TWMW0T0As/n/DazgZ05v8dU4v44kfvjOPfFidwfJ3J/nMj9cVw97YvFKaWeU62Y0oFsIkTEmpTSqqLrmCzcHydyfxznvjiR++NE7o8TuT+Oc1+U2WUpSZJUMAOZJElSwQxkZ/fJoguYZNwfJ3J/HOe+OJH740TujxO5P45zX+A5ZJIkSYWzhUySJKlgBrIziIgbI+LpiFgfEbcVXU/eImJRRHwvIp6IiMcj4t9ny2dFxN0R8Wz2ODNbHhHx8Wz/rIuIlcV+gnxERENE/CQivpHNL42IB7LP/cWIaM6Wt2Tz67P1SwotPAcR0RURd0bEUxHxZERcU6/HR0T8Rvbv5LGI+HxEtNbTsRERfx4ROyLisYplYz4WIuLmbPtnI+LmIj5LNZxmf/xh9m9lXUR8NSK6KtZ9ONsfT0fEWyuW18T3zqn2R8W634yIFBGzs/maPz5GJaXkzyl+gAZgA7AMaAYeAS4puq6cP/N8YGU23Qk8A1wC/Dfgtmz5bcAfZNNvB74FBHA18EDRnyGn/fJB4K+Ab2TzXwLenU1/Avi32fT7gE9k0+8Gvlh07TnsizuAf51NNwNd9Xh8AAuA54C2imPil+vp2ACuA1YCj1UsG9OxAMwCNmaPM7PpmUV/tiruj7cAjdn0H1Tsj0uy75QWYGn2XdNQS987p9of2fJFwHcojyE6u16Oj9H82EJ2elcC61NKG1NK/cAXgNUF15SrlNJLKaWHsukDwJOUv3hWU/4iJnu8KZteDXwmld0PdEXE/ImtOl8RsRD4aeBT2XwAbwLuzDY5eX+M7Kc7geuz7WtCRMyg/Ef20wAppf6U0l7q9/hoBNoiohGYBrxEHR0bKaXvA7tPWjzWY+GtwN0ppd0ppT3A3cCNuRefg1Ptj5TSd1NKg9ns/cDCbHo18IWUUl9K6TlgPeXvnJr53jnN8QHwUeBDQOUJ7DV/fIyGgez0FgCbK+a3ZMvqQtal8mrgAWBuSumlbNU2YG42XQ/76L9T/uMxnM13A3sr/shWfuZj+yNbvy/bvlYsBXqBv8i6cD8VEe3U4fGRUtoK/BHwAuUgtg9YS/0eGyPGeizU7DFyCv+KcisQ1On+iIjVwNaU0iMnrarL/XEyA5leJiI6gC8DH0gp7a9cl8rtyHVxaW5E/AywI6W0tuhaJolGyl0Qt6eUXg0cotwtdUy9HB/ZuVGrKYfU84B2avh/7uNRL8fCaETEfwIGgc8VXUtRImIa8B+B/1x0LZOVgez0tlLu6x6xMFtW0yKiiXIY+1xK6SvZ4u0jXU3Z445sea3vo9cD74iITZS7Dt4EfIxyc3pjtk3lZz62P7L1M4BdE1lwzrYAW1JKD2Tzd1IOaPV4fLwZeC6l1JtSGgC+Qvl4qddjY8RYj4VaPkYAiIhfBn4GeE8WUqE+98cFlP8D80j2N3Uh8FBEzKM+98fLGMhO70FgeXbVVDPlE3HvKrimXGXntHwaeDKl9CcVq+4CRq5uuRn4WsXy92ZXyFwN7KvorpjyUkofTiktTCktofz7//uU0nuA7wHvzDY7eX+M7Kd3ZtvXTAtBSmkbsDkiVmSLrgeeoD6PjxeAqyNiWvbvZmRf1OWxUWGsx8J3gLdExMys1fEt2bKaEBE3Uj7l4R0ppcMVq+4C3p1dfbsUWA78mBr+3kkpPZpSmpNSWpL9Td1C+SKybdTp8fEyRV9VMJl/KF/58Qzlq17+U9H1TMDnvZZyF8M64OHs5+2Uz3W5B3gW+DtgVrZ9AH+a7Z9HgVVFf4Yc981Pcfwqy2WU/3iuB/4aaMmWt2bz67P1y4quO4f9cAWwJjtG/obylU91eXwAvws8BTwGfJbyFXN1c2wAn6d8/twA5S/XW8ZzLFA+t2p99vMvi/5cVd4f6ymfAzXy9/QTFdv/p2x/PA28rWJ5TXzvnGp/nLR+E8evsqz542M0P47UL0mSVDC7LCVJkgpmIJMkSSqYgUySJKlgBjJJkqSCGcgkSZIKZiCTNKEi4mD2uCQi/kWVX/s/njT/o2q+frVFxC9HxP8sug5JxTOQSSrKEmBMgaxiFPzTOSGQpZReN8aappSIaCi6BknVYSCTVJSPAG+IiIcj4jcioiEi/jAiHoyIdRHxqwAR8VMR8YOIuIvyaPhExN9ExNqIeDwibs2WfQRoy17vc9mykda4yF77sYh4NCJ+vuK1742IOyPiqYj4XDby/gmybf4gIn4cEc9ExBuy5Se0cEXENyLip0beO3vPxyPi7yLiyux1NkbEOypeflG2/NmI+J2K1/rF7P0ejoj/PRK+stf944h4BLimSr8LSQU72/82JSkvtwH/IaX0MwBZsNqXUnptRLQAP4yI72bbrgQuSyk9l83/q5TS7ohoAx6MiC+nlG6LiH+XUrriFO/1zyjfZeByYHb2nO9n614NXAq8CPyQ8j0p/+EUr9GYUroyIt4O/A7l+1meSTvlWyT9VkR8Ffh94AbgEuAOjt8S50rgMuBwVtffUr5x+88Dr08pDUTE/wLeA3wme90HUkq/eZb3lzSFGMgkTRZvAV4VESP3gpxB+R5//cCPK8IYwK9HxD/Nphdl253pZt3XAp9PKQ1RvgH2fcBrgf3Za28BiIiHKXelniqQfSV7XJttczb9wLez6UeBvixcPXrS8+9OKe3K3v8rWa2DwGsoBzSANo7fqHsI+PIo3l/SFGIgkzRZBPBrKaUTbh6cdQEeOmn+zcA1KaXDEXEv5XtFjldfxfQQp/+72HeKbQY58dSPyjoG0vF70w2PPD+lNHzSuXAn378uUd4Xd6SUPnyKOo5mwVJSDfEcMklFOQB0Vsx/B/i3EdEEEBEXRUT7KZ43A9iThbGLgasr1g2MPP8kPwB+PjtPrQe4jvJNvs/VJuCKiChFxCLK3Y9jdUNEzMq6X2+i3G16D/DOiJgDkK1fXIV6JU1StpBJKso6YCg7Of0vgY9R7sp7KDuxvpdyQDnZt4F/ExFPAk8D91es+ySwLiIeSim9p2L5VymfAP8I5RaoD6WUtmWB7lz8EHiO8sUGTwIPjeM1fky5C3Ih8H9SSmsAIuL/Ab4bESVgAHg/8Pw51itpkorjLeqSJEkqgl2WkiRJBTOQSZIkFcxAJkmSVDADmSRJUsEMZJIkSQUzkEmSJBXMQCZJklQwA5kkSVLB/i/rFEmf0qhPIwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 35.50\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %.2f' % (100*test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
